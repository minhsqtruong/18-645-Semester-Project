//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21554848
// Cuda compilation tools, release 8.0, V8.0.61
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	_Z13i_add_latencyv
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[27] = {73, 110, 116, 101, 103, 101, 114, 32, 97, 100, 100, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str1[14] = {111, 117, 116, 112, 117, 116, 32, 105, 115, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str2[29] = {73, 110, 116, 101, 103, 101, 114, 32, 109, 105, 110, 117, 115, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str3[32] = {73, 110, 116, 101, 103, 101, 114, 32, 109, 117, 108, 116, 105, 112, 108, 121, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str4[30] = {73, 110, 116, 101, 103, 101, 114, 32, 109, 111, 100, 117, 108, 111, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str5[36] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 97, 100, 100, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str6[38] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 109, 105, 110, 117, 115, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str7[41] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 109, 117, 108, 116, 105, 112, 108, 121, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str8[39] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 100, 105, 118, 105, 100, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str9[41] = {73, 110, 116, 101, 103, 101, 114, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 97, 118, 101, 114, 97, 103, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str10[41] = {73, 110, 116, 101, 103, 101, 114, 32, 73, 110, 116, 114, 105, 115, 105, 99, 32, 109, 117, 108, 116, 105, 112, 108, 121, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str11[49] = {73, 110, 116, 101, 114, 103, 101, 114, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 97, 98, 115, 111, 108, 117, 116, 101, 32, 118, 97, 108, 117, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str12[49] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 99, 111, 115, 105, 110, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str13[47] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 115, 105, 110, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str14[46] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 97, 100, 100, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str15[49] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 100, 105, 118, 105, 100, 101, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str16[46] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 70, 77, 65, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};
.global .align 1 .b8 $str17[51] = {83, 105, 110, 103, 108, 101, 32, 80, 114, 101, 99, 105, 115, 105, 111, 110, 32, 73, 110, 116, 114, 105, 110, 115, 105, 99, 32, 109, 117, 108, 116, 105, 112, 108, 121, 32, 108, 97, 116, 101, 110, 99, 121, 58, 32, 37, 108, 108, 117, 10, 0};

.visible .entry _Z13i_add_latencyv(

)
{
	.local .align 8 .b8 	__local_depot0[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<33>;
	.reg .b64 	%rd<11>;


	mov.u64 	%rd10, __local_depot0;
	cvta.local.u64 	%SP, %rd10;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	mov.u32 	%r2, 0;
	mov.u32 	%r30, 1;
	// inline asm
	add.u32 %r1, %r2, %r30;
	// inline asm
	// inline asm
	add.u32 %r4, %r1, %r30;
	// inline asm
	// inline asm
	add.u32 %r7, %r4, %r30;
	// inline asm
	// inline asm
	add.u32 %r10, %r7, %r30;
	// inline asm
	// inline asm
	add.u32 %r13, %r10, %r30;
	// inline asm
	// inline asm
	add.u32 %r16, %r13, %r30;
	// inline asm
	// inline asm
	add.u32 %r19, %r16, %r30;
	// inline asm
	// inline asm
	add.u32 %r22, %r19, %r30;
	// inline asm
	// inline asm
	add.u32 %r25, %r22, %r30;
	// inline asm
	// inline asm
	add.u32 %r28, %r25, %r30;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd3, %rd2, %rd1;
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd5, %rd4;
	st.local.u64 	[%rd5], %rd3;
	mov.u64 	%rd6, $str;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r31, [retval0+0];
	
	//{
	}// Callseq End 0
	st.local.u32 	[%rd5], %r28;
	mov.u64 	%rd8, $str1;
	cvta.global.u64 	%rd9, %rd8;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r32, [retval0+0];
	
	//{
	}// Callseq End 1
	ret;
}

	// .globl	_Z13i_min_latencyv
.visible .entry _Z13i_min_latencyv(

)
{
	.local .align 8 .b8 	__local_depot1[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot1;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str2;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 2
	ret;
}

	// .globl	_Z13i_mul_latencyv
.visible .entry _Z13i_mul_latencyv(

)
{
	.local .align 8 .b8 	__local_depot2[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot2;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str3;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 3
	ret;
}

	// .globl	_Z13i_mod_latencyv
.visible .entry _Z13i_mod_latencyv(

)
{
	.local .align 8 .b8 	__local_depot3[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot3;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str4;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 4
	ret;
}

	// .globl	_Z13f_add_latencyv
.visible .entry _Z13f_add_latencyv(

)
{
	.local .align 8 .b8 	__local_depot4[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot4;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str5;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 5
	ret;
}

	// .globl	_Z13f_min_latencyv
.visible .entry _Z13f_min_latencyv(

)
{
	.local .align 8 .b8 	__local_depot5[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot5;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str6;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 6
	ret;
}

	// .globl	_Z13f_mul_latencyv
.visible .entry _Z13f_mul_latencyv(

)
{
	.local .align 8 .b8 	__local_depot6[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot6;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str7;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 7
	ret;
}

	// .globl	_Z13f_div_latencyv
.visible .entry _Z13f_div_latencyv(

)
{
	.local .align 8 .b8 	__local_depot7[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot7;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str8;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 8
	ret;
}

	// .globl	_Z11had_latencyv
.visible .entry _Z11had_latencyv(

)
{
	.local .align 8 .b8 	__local_depot8[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot8;
	cvta.local.u64 	%SP, %rd8;
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str9;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 9
	ret;
}

	// .globl	_Z13mul24_latencyv
.visible .entry _Z13mul24_latencyv(

)
{
	.local .align 8 .b8 	__local_depot9[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot9;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str10;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 10
	ret;
}

	// .globl	_Z11sad_latencyv
.visible .entry _Z11sad_latencyv(

)
{
	.local .align 8 .b8 	__local_depot10[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot10;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str11;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 11
	ret;
}

	// .globl	_Z12cosf_latencyv
.visible .entry _Z12cosf_latencyv(

)
{
	.local .align 8 .b8 	__local_depot11[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot11;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str12;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 12
	ret;
}

	// .globl	_Z12sinf_latencyv
.visible .entry _Z12sinf_latencyv(

)
{
	.local .align 8 .b8 	__local_depot12[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot12;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str13;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 13
	ret;
}

	// .globl	_Z15fadd_rd_latencyv
.visible .entry _Z15fadd_rd_latencyv(

)
{
	.local .align 8 .b8 	__local_depot13[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot13;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str14;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 14
	ret;
}

	// .globl	_Z15fdiv_rd_latencyv
.visible .entry _Z15fdiv_rd_latencyv(

)
{
	.local .align 8 .b8 	__local_depot14[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot14;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str15;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 15
	ret;
}

	// .globl	_Z15fmaf_rd_latencyv
.visible .entry _Z15fmaf_rd_latencyv(

)
{
	.local .align 8 .b8 	__local_depot15[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot15;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str16;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 16
	ret;
}

	// .globl	_Z15fmul_rd_latencyv
.visible .entry _Z15fmul_rd_latencyv(

)
{
	.local .align 8 .b8 	__local_depot16[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<9>;


	mov.u64 	%rd8, __local_depot16;
	cvta.local.u64 	%SP, %rd8;
	// inline asm
	mov.u64 	%rd1, %clock64;
	// inline asm
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	// inline asm
	mov.u64 	%rd2, %clock64;
	// inline asm
	sub.s64 	%rd5, %rd2, %rd1;
	st.local.u64 	[%rd4], %rd5;
	mov.u64 	%rd6, $str17;
	cvta.global.u64 	%rd7, %rd6;
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r1, [retval0+0];
	
	//{
	}// Callseq End 17
	ret;
}


